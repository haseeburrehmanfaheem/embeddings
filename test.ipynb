{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 15 20:14:29 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     Off |   00000000:61:00.0 Off |                    0 |\n",
      "|  0%   24C    P8             21W /  300W |       0MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u1/hfaheem/.conda/envs/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n",
      "Dimension of the embedding: 256, with norm=1.0\n",
      "tensor([ 0.0185,  0.0229, -0.0315, -0.0307, -0.1421, -0.0575, -0.0275,  0.0501,\n",
      "         0.0203,  0.0337, -0.0067, -0.0075, -0.0222, -0.0107, -0.0250, -0.0657,\n",
      "         0.1571, -0.0994, -0.0370,  0.0164, -0.0948,  0.0490, -0.0352,  0.0907,\n",
      "        -0.0198,  0.0130, -0.0921,  0.0209,  0.0651,  0.0319,  0.0299, -0.0173,\n",
      "        -0.0693, -0.0798, -0.0066, -0.0417,  0.1076,  0.0597, -0.0316,  0.0940,\n",
      "        -0.0313,  0.0993,  0.0931, -0.0427,  0.0256,  0.0297, -0.0561, -0.0155,\n",
      "        -0.0496, -0.0697, -0.1011,  0.1178,  0.0283, -0.0571, -0.0635, -0.0222,\n",
      "         0.0710, -0.0617,  0.0423, -0.0057,  0.0620, -0.0262,  0.0441,  0.0425,\n",
      "        -0.0413, -0.0245,  0.0043,  0.0185,  0.0060, -0.1727, -0.1152,  0.0655,\n",
      "        -0.0235, -0.1465, -0.1359,  0.0022,  0.0177, -0.0176, -0.0361, -0.0750,\n",
      "        -0.0464, -0.0846, -0.0088,  0.0136, -0.0221,  0.0591,  0.0876, -0.0903,\n",
      "         0.0271, -0.1165, -0.0169, -0.0566,  0.1173, -0.0801,  0.0430,  0.0236,\n",
      "         0.0060, -0.0778, -0.0570,  0.0102, -0.0172, -0.0051, -0.0891, -0.0620,\n",
      "        -0.0536,  0.0190, -0.0039, -0.0189, -0.0267, -0.0389, -0.0208,  0.0076,\n",
      "        -0.0676,  0.0630, -0.0962,  0.0418, -0.0172, -0.0229, -0.0452,  0.0401,\n",
      "         0.0270,  0.0677, -0.0111, -0.0089,  0.0175,  0.0703,  0.0714, -0.0068,\n",
      "         0.1214, -0.0004,  0.0020,  0.0255,  0.0424, -0.0030,  0.0318,  0.1227,\n",
      "         0.0676, -0.0723,  0.0970,  0.0637, -0.0140, -0.0283, -0.0120,  0.0343,\n",
      "        -0.0890,  0.0680,  0.0514,  0.0513,  0.0627, -0.0284, -0.0479,  0.0068,\n",
      "        -0.0794,  0.0202,  0.0208, -0.0113, -0.0747,  0.0045, -0.0854, -0.0609,\n",
      "        -0.0078,  0.1168,  0.0618, -0.0223, -0.0755,  0.0182, -0.0128,  0.1116,\n",
      "         0.0240,  0.0342,  0.0119, -0.0235, -0.0150, -0.0228, -0.0568, -0.1528,\n",
      "         0.0164, -0.0268,  0.0727, -0.0569,  0.1306,  0.0643, -0.0158, -0.1070,\n",
      "        -0.0107, -0.0139, -0.0363,  0.0366, -0.0986, -0.0628, -0.0277,  0.0316,\n",
      "         0.0363,  0.0038, -0.1092, -0.0679, -0.1398, -0.0648,  0.1711, -0.0666,\n",
      "         0.0563,  0.0581,  0.0226,  0.0347, -0.0672, -0.0229, -0.0565,  0.0623,\n",
      "         0.1089, -0.0687, -0.0901, -0.0073,  0.0426,  0.0870, -0.0390, -0.0144,\n",
      "        -0.0166,  0.0262, -0.0310,  0.0467, -0.0164, -0.0700, -0.0602, -0.0720,\n",
      "        -0.0386,  0.0067, -0.0337, -0.0053,  0.0829,  0.1004,  0.0427,  0.0026,\n",
      "        -0.0537,  0.0951,  0.0584, -0.0583, -0.0208,  0.0124,  0.0067,  0.0403,\n",
      "         0.0091, -0.0044, -0.0036,  0.0524,  0.1103, -0.1511, -0.0479,  0.1709,\n",
      "         0.0772,  0.0721, -0.0332,  0.0866,  0.0799, -0.0581,  0.0713,  0.0218],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codet5p-110m-embedding\"\n",
    "device = \"cuda\"  # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)\n",
    "\n",
    "inputs = tokenizer.encode(\"def print_hello_world():\\tprint('Hello World!')\", return_tensors=\"pt\").to(device)\n",
    "embedding = model(inputs)[0]\n",
    "print(embedding.size())\n",
    "print(f'Dimension of the embedding: {embedding.size()[0]}, with norm={embedding.norm().item()}')\n",
    "# Dimension of the embedding: 256, with norm=1.0\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_embedding(code_snippet, checkpoint=\"Salesforce/codet5p-110m-embedding\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a given code snippet using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - code_snippet (str): The code for which embeddings are to be generated.\n",
    "    - checkpoint (str): The model checkpoint to be used for embedding. Default is Salesforce/codet5p-110m-embedding.\n",
    "    - device (str): Device to run the model on, either 'cuda' for GPU or 'cpu' for CPU. Default is 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Embedding tensor for the input code.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)\n",
    "    \n",
    "    inputs = tokenizer.encode(code_snippet, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(inputs)[0]\n",
    "    \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([256])\n",
      "Embedding shape: torch.Size([256])\n",
      "Embedding shape: torch.Size([256])\n",
      "Embedding shape: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "code_snippet1 = \"\"\"\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\"\"\"\n",
    "embedding1 = get_code_embedding(code_snippet1, device=\"cuda\")\n",
    "print(f\"Embedding shape: {embedding1.size()}\")\n",
    "\n",
    "code_snippet2 = \"\"\"\n",
    "def sum_values(a, b):\n",
    "    return a + b\n",
    "\"\"\"\n",
    "embedding2 = get_code_embedding(code_snippet2, device=\"cuda\")\n",
    "print(f\"Embedding shape: {embedding2.size()}\")\n",
    "\n",
    "code_snippet3 = \"\"\"\n",
    "def sum_values(x, y):\n",
    "    a = 42\n",
    "    b = 17\n",
    "    c = a - b + 8\n",
    "    d = c * 3 - 10\n",
    "    return x + y\n",
    "\"\"\"\n",
    "embedding3 = get_code_embedding(code_snippet3, device=\"cuda\")\n",
    "print(f\"Embedding shape: {embedding3.size()}\")\n",
    "\n",
    "code_snippet4 = \"\"\"\n",
    "\n",
    "def sum_values(x, y):\n",
    "    a = 42\n",
    "    b = 17\n",
    "    c = a - b + 8\n",
    "    d = c * 3 - 10\n",
    "    return a + b\n",
    "\"\"\"\n",
    "embedding4 = get_code_embedding(code_snippet4, device=\"cuda\")\n",
    "print(f\"Embedding shape: {embedding4.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8219677209854126\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = F.cosine_similarity(embedding2, embedding3, dim=0)\n",
    "print(f'Cosine similarity: {cosine_sim.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jadx examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between j1 and j2: 0.8550946712493896\n",
      "Cosine similarity between j1 and j3: 0.710127592086792\n",
      "Cosine similarity between j1 and j4: 0.7475813627243042\n",
      "Cosine similarity between j1 and j5: 0.7092236280441284\n",
      "Cosine similarity between j2 and j3: 0.8119555115699768\n",
      "Cosine similarity between j2 and j4: 0.8571170568466187\n",
      "Cosine similarity between j2 and j5: 0.8091253042221069\n",
      "Cosine similarity between j3 and j4: 0.8190112709999084\n",
      "Cosine similarity between j3 and j5: 0.9439752101898193\n",
      "Cosine similarity between j4 and j5: 0.8089645504951477\n"
     ]
    }
   ],
   "source": [
    "j1 = \"\"\"\n",
    "public void uncacheShortcuts(String str, String str2, List<String> list, UserHandle userHandle, int i) {\n",
    "            ensureStrictAccessShortcutsPermission(str);\n",
    "            if (canAccessProfile(userHandle.getIdentifier(), \"Cannot uncache shortcuts\")) {\n",
    "                this.mShortcutServiceInternal.uncacheShortcuts(getCallingUserId(), str, str2, list, userHandle.getIdentifier(), toShortcutsCacheFlags(i));\n",
    "            }\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "j2 = \"\"\"\n",
    "@Override // android.content.pm.ILauncherApps\n",
    "        public void cacheShortcuts(String str, String str2, List<String> list, UserHandle userHandle, int i) {\n",
    "            ensureStrictAccessShortcutsPermission(str);\n",
    "            if (canAccessProfile(userHandle.getIdentifier(), \"Cannot cache shortcuts\")) {\n",
    "                this.mShortcutServiceInternal.cacheShortcuts(getCallingUserId(), str, str2, list, userHandle.getIdentifier(), toShortcutsCacheFlags(i));\n",
    "            }\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "j3 = \"\"\"\n",
    "@Override // android.content.pm.ILauncherApps\n",
    "        public int getShortcutIconResId(String str, String str2, String str3, int i) {\n",
    "            ensureShortcutPermission(str);\n",
    "            if (canAccessProfile(i, \"Cannot access shortcuts\")) {\n",
    "                return this.mShortcutServiceInternal.getShortcutIconResId(getCallingUserId(), str, str2, str3, i);\n",
    "            }\n",
    "            return 0;\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "j4 = \"\"\"\n",
    "@Override // android.content.pm.ILauncherApps\n",
    "        public void pinShortcuts(String str, String str2, List<String> list, UserHandle userHandle) {\n",
    "            ensureShortcutPermission(str);\n",
    "            if (canAccessProfile(userHandle.getIdentifier(), \"Cannot pin shortcuts\")) {\n",
    "                this.mShortcutServiceInternal.pinShortcuts(getCallingUserId(), str, str2, list, userHandle.getIdentifier());\n",
    "            }\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "j5 = \"\"\"\n",
    "@Override // android.content.pm.ILauncherApps\n",
    "        public String getShortcutIconUri(String str, String str2, String str3, int i) {\n",
    "            ensureShortcutPermission(str);\n",
    "            if (canAccessProfile(i, \"Cannot access shortcuts\")) {\n",
    "                AndroidFuture<String> androidFuture = new AndroidFuture<>();\n",
    "                this.mShortcutServiceInternal.getShortcutIconUriAsync(getCallingUserId(), str, str2, str3, i, androidFuture);\n",
    "                try {\n",
    "                    return androidFuture.get();\n",
    "                } catch (InterruptedException | ExecutionException e2) {\n",
    "                    throw new RuntimeException(e2);\n",
    "                }\n",
    "            }\n",
    "            return null;\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# trace event taken from j2\n",
    "trace_events = \"\"\"\n",
    "this.mShortcutServiceInternal.cacheShortcuts(getCallingUserId(), str, str2, list, userHandle.getIdentifier(), toShortcutsCacheFlags(i));\n",
    "\"\"\"\n",
    "\n",
    "# get embedding for the trace event \n",
    "embedding_trace_event = get_code_embedding(trace_events, device=\"cuda\")\n",
    "\n",
    "\n",
    "embedding_j1 = get_code_embedding(j1, device=\"cuda\")\n",
    "embedding_j2 = get_code_embedding(j2, device=\"cuda\")\n",
    "embedding_j3 = get_code_embedding(j3, device=\"cuda\")\n",
    "embedding_j4 = get_code_embedding(j4, device=\"cuda\")\n",
    "embedding_j5 = get_code_embedding(j5, device=\"cuda\")\n",
    "\n",
    "list = [embedding_j1, embedding_j2, embedding_j3, embedding_j4, embedding_j5]\n",
    "\n",
    "for i in range(5):\n",
    "  for j in range(i+1, 5):\n",
    "    cosine_sim = F.cosine_similarity(list[i], list[j], dim=0)\n",
    "    print(f'Cosine similarity between j{i+1} and j{j+1}: {cosine_sim.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between trace event and j1: 0.804334819316864\n",
      "Cosine similarity between trace event and j2: 0.8724206686019897\n",
      "Cosine similarity between trace event and j3: 0.6814613342285156\n",
      "Cosine similarity between trace event and j4: 0.728966474533081\n",
      "Cosine similarity between trace event and j5: 0.6645785570144653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "  cosine_sim_trace_j = F.cosine_similarity(embedding_trace_event, list[i], dim=0)\n",
    "  print(f'Cosine similarity between trace event and j{i+1}: {cosine_sim_trace_j.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
